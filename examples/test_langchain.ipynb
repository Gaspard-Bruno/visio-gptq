{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcojoao/mambaforge/envs/vicuna/lib/python3.10/site-packages/safetensors/torch.py:99: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  with safe_open(filename, framework=\"pt\", device=device) as f:\n",
      "/home/marcojoao/mambaforge/envs/vicuna/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "/home/marcojoao/mambaforge/envs/vicuna/lib/python3.10/site-packages/torch/storage.py:899: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = cls(wrap_storage=untyped_storage)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from src.model import GPTQModel\n",
    "model = GPTQModel(model_name=\"/data/repos/visio-gptq/models/vicuna-13b-GPTQ-4bit-128g\", device=\"cuda\", wbits=4, groupsize=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms.base import LLM\n",
    "from typing import Optional, List\n",
    "\n",
    "class GPTQModelLLM(LLM):\n",
    "    model: GPTQModel\n",
    "    params: dict = {}\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"gptq_model_llm\"\n",
    "\n",
    "    def callbackFunc(self,txt):\n",
    "        print(txt, end=\" \", flush=True)\n",
    "\n",
    "    def _call(self, prompt:str, stop: Optional[List[str]] = None) -> str:\n",
    "        current_stop = self.params.get(\"stop\", [])\n",
    "        if stop is not None:\n",
    "            current_stop.extend(stop)\n",
    "            self.params[\"stop\"] = current_stop\n",
    "\n",
    "        conv = model.inference(prompt=prompt, **self.params)\n",
    "        if isinstance(conv, str):\n",
    "            return conv\n",
    "        return \"Error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "llm = GPTQModelLLM(model=model, params={\"temperature\": 0.0, \"stop\":[\"Question:\", \"###\"]})\n",
    "DEFAULT_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"history\",\"input\"],\n",
    "    template=\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\"\n",
    "            \"Current conversation:\"\n",
    "            \"{history}\"\n",
    "            \"### Human: {input}\"\n",
    "            \"### AI:\")\n",
    "conv = ConversationChain(llm=llm, prompt=DEFAULT_PROMPT, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Rede Natura 2000\" is a network of nature protection areas in the European Union. The main factors of Rede Natura 2000 are:\n",
      "\n",
      "1. Biodiversity conservation\n",
      "2. Habitat protection\n",
      "3. Species protection\n",
      "4. Sustainable use of natural resources\n",
      "5. Climate change mitigation and adaptation.\n"
     ]
    }
   ],
   "source": [
    "result = conv.predict(input=\"Prepate this question to be optimized for matching in Vector Databases: 'What is the main factors of Rede Natura 2000'\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of Spain is Madrid.\n",
      "\n",
      "Madrid is the largest city in Spain and it is located in the center of the country. It is a major economic, financial, and cultural center, and it is known for its vibrant culture, art museums, and historic architecture. Some popular tourist attractions in Madrid include the Puerta del Sol, the Plaza Mayor, the Royal Palace of Madrid, and the Prado Museum.\n",
      "\n",
      "Spain is a country located in southwestern Europe, and it is bordered by the Atlantic Ocean to the northwest and the Mediterranean Sea to the southeast. It is a member of the European Union and the Schengen Area, and it shares land borders with France and Andorra to the northeast, and Portugal and Morocco to the southwest. Spain has a population of about 47 million people and its official languages are Spanish and Catalan.\n"
     ]
    }
   ],
   "source": [
    "result = conv.predict(input=\"and Spain?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your first question was \"What is the capital of Portugal?\"\n"
     ]
    }
   ],
   "source": [
    "result = conv.predict(input=\"What was my first question?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.agents import initialize_agent, load_tools\n",
    "from langchain.agents import AgentType\n",
    "\n",
    "import os\n",
    "os.environ[\"SERPAPI_API_KEY\"] = \"0b04c97ae0b36c75255caab4699edec201637d03c725226e74fc029f239ee773\"\n",
    "\n",
    "tools = load_tools([\"serpapi\"])\n",
    "agent = initialize_agent(tools=tools, llm=llm, memory=memory, agent=\"zero-shot-react-description\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to know the cheapest car in StandVirtual, in Portugal\n",
      "Action: Search\n",
      "Action Input: StandVirtual car cheapest Portugal\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mTrigo & Falcão Car. Com garantia ... Carros em Portugal. Lisboa11 481 · Porto10 189 · Braga4 757 · Setúbal3 794 · Aveiro2 834 · Leiria2 615 · Santarém1 769 ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: Trigo & Falcão Car. Com garantia ... Carros em Portugal.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Trigo & Falcão Car. Com garantia ... Carros em Portugal.'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(input=\"What is the the chepeast car in StandVirtual, in Portugal?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vicuna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
