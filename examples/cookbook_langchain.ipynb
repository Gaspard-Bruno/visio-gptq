{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcojoao/mambaforge/envs/vicuna/lib/python3.10/site-packages/safetensors/torch.py:99: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  with safe_open(filename, framework=\"pt\", device=device) as f:\n",
      "/home/marcojoao/mambaforge/envs/vicuna/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "/home/marcojoao/mambaforge/envs/vicuna/lib/python3.10/site-packages/torch/storage.py:899: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = cls(wrap_storage=untyped_storage)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from visio_gptq.model import GPTQModel\n",
    "model = GPTQModel(model_name=\"TheBloke/wizardLM-7B-GPTQ\", device=\"cuda\", wbits=4, groupsize=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms.base import LLM\n",
    "from typing import Optional, List\n",
    "\n",
    "class GPTQModelLLM(LLM):\n",
    "    model: GPTQModel\n",
    "    params: dict = {}\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"gptq_model_llm\"\n",
    "\n",
    "    def callbackFunc(self,txt):\n",
    "        print(txt, end=\" \", flush=True)\n",
    "\n",
    "    def _call(self, prompt:str, stop: Optional[List[str]] = None) -> str:\n",
    "        current_stop = self.params.get(\"stop\", [])\n",
    "        if stop is not None:\n",
    "            current_stop.extend(stop)\n",
    "            self.params[\"stop\"] = current_stop\n",
    "\n",
    "        verbose = self.params.get(\"verbose\", self.verbose)\n",
    "        output = \"\"\n",
    "        generator = model.generate_stream(prompt=prompt, **self.params)\n",
    "        for result in generator:\n",
    "            output += \" \" + result\n",
    "            if verbose:\n",
    "                print(result, end=\" \", flush=True)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "llm = GPTQModelLLM(model=model, params={\"verbose\":True, \"temperature\": 0.7})\n",
    "DEFAULT_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"history\",\"input\"],\n",
    "    template=\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\"\n",
    "            \"Current conversation:\"\n",
    "            \"###Human: Give three tips for staying healthy.\"\n",
    "            \"###AI: Sure, here are three tips for staying healthy:\"\n",
    "            \"1. Exercise regularly: Regular physical activity can help improve your overall health and wellbeing. It can also help reduce your risk of chronic conditions such as obesity, diabetes, heart disease, and certain cancers. Aim for at least 150 minutes of moderate-intensity aerobic exercise or 75 minutes of vigorous-intensity aerobic exercise per week, along with muscle-strengthening activities at least two days per week.\"\n",
    "            \"2. Eat a balanced diet: Eating a balanced diet that is rich in fruits, vegetables, whole grains, lean proteins, and healthy fats can help support your overall health. Try to limit your intake of processed and high-sugar foods, and aim to drink plenty of water throughout the day.\"\n",
    "            \"3. Get enough sleep: Getting enough quality sleep is essential for your physical and mental health. Adults should aim for seven to nine hours of sleep per night. Establish a regular sleep schedule and try to create a relaxing bedtime routine to help improve the quality of your sleep.\"\n",
    "            \"{history}\"\n",
    "            \"###Human: {input}\"\n",
    "            \"###AI:\")\n",
    "conv = ConversationChain(llm=llm, prompt=DEFAULT_PROMPT, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To replace part of a text from various cells in Microsoft Excel without changing the format of the entire cell, you can use the \"Find and Replace\" feature. First, select the cell or range of cells where you want to replace the text. Then, click on the \"Find and Replace\" button in the \"Home\" tab of the Excel ribbon. In the \"Find What\" field, enter the text you want to replace. In the \"Replace With\" field, enter the new text you want to replace the old text with. Make sure the \"Search Format\" option is set to \"Regular Expressions\" and the \"Find All\" option is checked. Then, click \"Replace All\" to replace the text in all selected cells. "
     ]
    }
   ],
   "source": [
    "result = conv.predict(input=\"In Microsoft Excel, how do I replace part of a text from various cells without changing the format of the entire cell?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import OnlinePDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "detectron2 is not installed. Cannot use the hi_res partitioning strategy. Falling back to partitioning with the fast strategy.\n",
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    }
   ],
   "source": [
    "data = OnlinePDFLoader(\"https://arxiv.org/pdf/2304.12244v1.pdf\").load()\n",
    "texts = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0).split_documents(data)\n",
    "docsearch = Chroma.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WizardLM is an AI assistant that empowers large language models to follow complex instructions. It uses Evol-Instruct, a dataset construction method, to improve the effectiveness of language models in various domains. WizardLM has achieved significant results in the experiment, outperforming Alpaca and Vicuna-7b on high-difÔ¨Åculty skills. It can perform well on various skills such as writing, math, biology, chemistry, and physics. Overall, WizardLM is an effective tool for solving complex problems with the help of language models. "
     ]
    }
   ],
   "source": [
    "query = \"write a summary about WizardLM in 100 words\"\n",
    "docs = docsearch.similarity_search(query, include_metadata=True, top_k=5)\n",
    "chain = load_qa_chain(llm=llm, chain_type=\"stuff\")\n",
    "result = chain.run(input_documents=docs, question=query, verbose=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vicuna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
