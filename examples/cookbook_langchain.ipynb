{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcojoao/mambaforge/envs/vicuna/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcojoao/mambaforge/envs/vicuna/lib/python3.10/site-packages/safetensors/torch.py:99: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  with safe_open(filename, framework=\"pt\", device=device) as f:\n",
      "/home/marcojoao/mambaforge/envs/vicuna/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "/home/marcojoao/mambaforge/envs/vicuna/lib/python3.10/site-packages/torch/storage.py:899: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = cls(wrap_storage=untyped_storage)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from visio_gptq.model import GPTQModel\n",
    "model = GPTQModel(model_name=\"anon8231489123/vicuna-13b-GPTQ-4bit-128g\", device=\"cuda\", wbits=4, groupsize=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms.base import LLM\n",
    "from typing import Optional, List\n",
    "\n",
    "class GPTQModelLLM(LLM):\n",
    "    model: GPTQModel\n",
    "    params: dict = {}\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"gptq_model_llm\"\n",
    "\n",
    "    def callbackFunc(self,txt):\n",
    "        print(txt, end=\" \", flush=True)\n",
    "\n",
    "    def _call(self, prompt:str, stop: Optional[List[str]] = None) -> str:\n",
    "        current_stop = self.params.get(\"stop\", [])\n",
    "        if stop is not None:\n",
    "            current_stop.extend(stop)\n",
    "            self.params[\"stop\"] = current_stop\n",
    "\n",
    "        conv = model.inference(prompt=prompt, **self.params)\n",
    "        if isinstance(conv, str):\n",
    "            return conv\n",
    "        return \"Error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "llm = GPTQModelLLM(model=model, params={\"temperature\": 0.0, \"stop\":[\"Question:\", \"###\"]})\n",
    "DEFAULT_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"history\",\"input\"],\n",
    "    template=\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides direct answers based only on context. If the AI does not know the answer to a question, it truthfully says it does not know.\"\n",
    "            \"Current conversation:\"\n",
    "            \"{history}\"\n",
    "            \"### Human: {input}\"\n",
    "            \"### AI:\")\n",
    "conv = ConversationChain(llm=llm, prompt=DEFAULT_PROMPT, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of Portugal is Lisbon.\n",
      "\n",
      "Lisbon is the largest city in Portugal, and it is located on the Atlantic coast in the western part of the country. It is a major economic, financial, and cultural center, and it is known for its historic architecture, museums, and cultural events. Lisbon is also a popular tourist destination, and it is famous for its picturesque neighborhoods, traditional cuisine, and vibrant nightlife.\n"
     ]
    }
   ],
   "source": [
    "result = conv.predict(input=\"What is the capital of Portugal?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of Spain is Madrid.\n",
      "\n",
      "Madrid is the largest city in Spain and it is located in the center of the country. It is a major economic, political, and cultural center, and it is known for its vibrant atmosphere, cultural attractions, and historical landmarks. Madrid is home to some of the world's most famous museums, including the Prado Museum, which houses an extensive collection of European art, and the Reina Sofia Museum, which is dedicated to modern and contemporary art. The city is also famous for its lively nightlife, delicious food, and beautiful architecture.\n"
     ]
    }
   ],
   "source": [
    "result = conv.predict(input=\"and Spain?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your first question was: \"What is the capital of Portugal?\"\n"
     ]
    }
   ],
   "source": [
    "result = conv.predict(input=\"What was my first question?\")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vicuna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
